---
title: "Cours"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
# source("C:/Users/Tom/Documents/Cours/Polytech/4A/4A/S1/Analyse_données/PROJET/codageR_TOTAL_R_MARDOWN_EC_BT.R")  
source("My_function.R") 


#librairies
library(DataCombine)
library(prodlim)
library(binom)
library(gsDesign)
library(cvAUC)
library(caret)
library(vcd)
library(greyzoneSurv)
library(mgcv)
library(randomForest)
library(datasets)
library(keras)
library(mlbench)
library(magrittr)
library(neuralnet)
library(tensorflow)
library(openxlsx)
library(broom)
library(flextable)
#library(idefix)
library(magrittr)
library(dplyr)
library(officer)
library(stringr)
library(forcats)
library(regclass)
library(car)
library(epiDisplay)
library(caTools)
library(ggcorrplot)
#library(questionr)
library(plotly)
library(MASS)
library(GGally)
library(broom.helpers)
library(forestmodel)
library(xgboost)
library(Matrix)
library(flextable)
library(pROC)
library(skimr)
library(Amelia)
```

```{r}
dff = read.csv("data.csv", 
              sep=",", dec=".")

names(dff)[names(dff) == "MSSubClass"] <- "type_bien"
names(dff)[names(dff) == "MSZoning"] <- "zone"
names(dff)[names(dff) == "LotFrontage"] <-"dist_voisin"
names(dff)[names(dff) == "LotArea"] <- "Surface_quartier"
names(dff)[names(dff) == "Street"] <- "street_acces"
names(dff)[names(dff) == "Alley"] <- "alley_acces"
names(dff)[names(dff) == "LotShape"] <- "Forme_bien"
names(dff)[names(dff) == "LandContour"] <- "pendage"
names(dff)[names(dff) == "LotConfig"] <- "config"
names(dff)[names(dff) == "Neighborhood"] <- "dispo_proche"
names(dff)[names(dff) == "LotConfig"] <- "config"

dff$zone<-fct_recode(dff$zone, "0" = "C (all)","1"="FV", "2" = "RH","3"="RL","4"="RM")
dff$street_acces<-fct_recode(dff$street_acces,"1"= "Grvl","2"= "Pave")
dff$alley_acces[is.na(dff$alley_acces)] <- 0
dff$alley_acces<-fct_recode(dff$alley_acces,"1"= "Grvl","2"= "Pave")
dff$Forme_bien<-fct_recode(dff$Forme_bien,"0"= "Reg","1"= "IR1","2"= "IR2","3"= "IR3")
dff$pendage<-fct_recode(dff$pendage, "0"="Lvl","1"="Bnk" ,"2"= "HLS" ,"3"="Low")
dff$config<-fct_recode(dff$config, "0"="Inside","1"="Corner", "2"="CulDSac","3"="FR2","3"="FR3")
dff$dispo_proche<-fct_recode(dff$dispo_proche, "0"="Blmngtn","1"="Blueste","2"= "BrDale" ,"3"="BrkSide","4"="ClearCr","5"= "CollgCr", "6"="Crawfor", "7"="Edwards","8"="Gilbert","9"="IDOTRR","10"="MeadowV","11"="Mitchel","12"="NAmes", "13"="NoRidge","14"="NPkVill", "15"="NridgHt", "16"="NWAmes", "17"="OldTown","18"="SWISU","19"="SWISU","20"="Sawyer","21"="SawyerW","22"="SawyerW","23"="Somerst","24"="StoneBr","25"="Timber","26"="Veenker")
dff$SalePrice<-cut(dff$SalePrice, 5)


colname_chara<-c(2,10,12,14:19,22:26,28:34,36,40:43,54,56,58,59,61,64:66,73:75,79,80)
dff[,colname_chara] = lapply( dff[,colname_chara] , as.factor)

cols_to_supress=c(10)
dff = subset(dff, select = -cols_to_supress )
rm(cols_to_supress)
```

# Analyse descriptive
```{r Ecoutez}
dim(dff)
set.seed(12345)
```
## Analyse des variables qualitatives
```{r Ecoutez}
index=c(2:3,6:18,21:25,27:33,35,39:42,53,55,57,58,60,63:65,72:74)
ft=sortiequali(as.data.frame(dff),index)
ft=md_table(ft)
ft
rm(ft,index)
```
## Analyse des variables quantitative
```{r Ecoutez}
index=c(1,4,5,19,20,26,34,36,37,38,43:52,54,56,59,61,62,66:71,75:77)
ft=sortiequanti(as.data.frame(dff),index)
ft=md_table(ft)
ft
rm(ft,index)
```

## Création de sous groupes en fonction du centre 
```{r Ecoutez ,echo=T}
appren_int<-sample(nrow(dff),nrow(dff)*0.7)#récupération des indices de l'échantillon
train<-dff[appren_int,]
test<-dff[-appren_int,]
```
## Analyse descriptive des deux cohorte pareil que précédement 
...
...

# Analyse uni-variée
## Analyse statistique de toutes les varaibles en fonction de la variable cancer 
```{r Balec}
#index=c(2:3,6:18,21:25,27:33,35,39:42,53,55,57,58,60,63:65,72:74)+1
#train %>% relocate(SalePrice)
train<-train %>% relocate(SalePrice, .before = Id)
```


```{r Ecoutez}
train<-drop_level_0_and_unassociate(train,1)
```


```{r}
# cols_to_supress=c()
# train = subset(train, select = -cols_to_supress )
# rm(cols_to_supress)
# table(dff$MiscFeature,dff$SalePrice)
```


```{r Balec}
dim(train)
a_drop<-c()
for(i in 1:ncol(train))
  {
  if (is.factor(train[,i])==TRUE)
    {
    if (any(table(train[[i]])<=2) )
      {
      a_drop<-c(a_drop,i)
      next
      }
    }
}
train[,1]<-droplevels(train[,1])
table(train$SalePrice)
a_drop
```

```{r Balec}
cols_to_supress=c(7, 13, 14, 15, 18, 22, 23, 24, 25, 29, 32, 40, 41, 43, 65, 77, 78)
train = subset(train, select = -cols_to_supress )
rm(cols_to_supress)
dim(train)
```


```{r Ecoutez}
tt=tableStack(vars=3:61,
              by=1,
              dataFrame=as.data.frame(train),
              na.col=T)
bold_lines=which(tt[,1] %in% colnames(train))#Met les noms en gras
colnames(tt)[1:6]=c("Vente","Tranche1","Tranche2","Tranche3","Tranche4","Tranche5") #on attribue les noms des colones
md_table(tt,bold.names=bold_lines)
```

```{r Ecoutez}
signif=c(3,4,5,6,7,8,9,10,12,13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41,42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57)
```

## On crée un nouveau data-frame ne contenant que les variables significatives et la variable cancer
```{r Ecoutez}
train_nett<-train[,c(1,signif)]
dim(train_nett)
```
# Analyse multivarée 
## Suppression des lignes contenant un Na 
```{r Ecoutez}
train_nett<-na.omit(train_nett)
dim(train_nett)
names(train_nett)
```

```{r Ecoutez}
formula = as.formula("SalePrice~type_bien+zone+dist_voisin+Surface_quartier+alley_acces+Forme_bien+pendage+config+OverallCond+YearBuilt+YearRemodAdd+MasVnrType+MasVnrArea+ExterQual+Foundation+BsmtQual+BsmtExposure+BsmtFinType1+BsmtFinSF1+BsmtFinSF2+BsmtUnfSF+CentralAir+X1stFlrSF+X2ndFlrSF+LowQualFinSF+BsmtFullBath+FullBath+HalfBath+BedroomAbvGr+KitchenAbvGr+KitchenQual+TotRmsAbvGrd+Functional+Fireplaces+FireplaceQu+GarageType+GarageYrBlt+GarageFinish+GarageCars+GarageArea+GarageQual+PavedDrive+WoodDeckSF+OpenPorchSF+EnclosedPorch+X3SsnPorch+ScreenPorch+PoolArea")
model = glm(formula, data=train_nett,family=binomial())
summary(model)
```
## Analyse corrélation 
```{r Balec}
ld.vars <- attributes(alias(model)$Complete)$dimnames[[1]]
ld.vars
```

```{r Ecoutez}
vif(model)
```
Supprimer les variable avec un VIF > 5

```{r Balec}
cols<-numcol(c("type_bien","zone","Forme_bien","OverallCond","YearBuilt","YearRemodAdd","MasVnrType","ExterQual","Foundation","BsmtQual","BsmtFinType1","BsmtFinSF1","BsmtUnfSF","X1stFlrSF","X2ndFlrSF","LowQualFinSF","KitchenAbvGr","KitchenQual","TotRmsAbvGrd","Functional","FireplaceQu","GarageType","GarageYrBlt","GarageCars","GarageArea","GarageQual"),train_nett)
train_nett<-train_nett[,-cols]
```

```{r Ecoutez}
formula = as.formula("SalePrice~dist_voisin+Surface_quartier+alley_acces+pendage+config+BldgType+HouseStyle+MasVnrArea+BsmtExposure+BsmtFinSF2+TotalBsmtSF+CentralAir+BsmtFullBath+FullBath+HalfBath+BedroomAbvGr+Fireplaces+GarageFinish+PavedDrive+WoodDeckSF+OpenPorchSF+EnclosedPorch+X3SsnPorch+ScreenPorch+PoolArea")
model_initial = glm(formula, data=train_nett,family=binomial())
summary(model_initial)
```
## Apprentissage 
### Minimisation de l'AIC
```{r Ecoutez}
model_final_cours<-stepAIC(model_initial)
```

### AIC finale
```{r Balec}
round(AIC(model_final_cours),digits=1)
```

### Modele final
```{r Ecoutez}
summary(model_final_cours)
```

```{r Ecoutez}
plot(model_final_cours)
```

### Analyse des odds ratio 
```{r Ecoutez,fig.height=5,fig.width=10}
forest_model(model_final_cours)
```

## Validation modèle 
### Accuracy sur la cohorte train 
```{r Ecoutez}
pred_train<-predict.glm(model_final_cours,train_nett,type="response")
accuracy_appren<-accuracy(pred_train,train_nett$SalePrice)
md_table(as.data.frame(accuracy_appren),fit=F)
```

### Accuracy sur la cohorte valid 
```{r Ecoutez}
pred_test<-predict.glm(model_final_cours,test,type="response")
accuracy_test<-accuracy(pred_test,test$SalePrice)
md_table(as.data.frame(accuracy_test),fit=F)
```
## Courbe de ROC
```{r Ecoutez}
roc_train<-roc(train_nett$SalePrice,pred_train)
roc_test<-roc(test$SalePrice,pred_test)
plot(roc_train,print.auc=T,print.auc.x=1.3,print.auc.y=1)
plot(roc_test,print.auc=T,col="green", print.auc.col="green",add=T,print.auc.x=1.3,print.auc.y=0.9)
legend(0.2, 0.2, c("Apprentissage","Validation"),col=c("black","green"), lty=1, cex=0.8)
# ci.auc(roc_train)
# ci.auc(roc_test)
```
